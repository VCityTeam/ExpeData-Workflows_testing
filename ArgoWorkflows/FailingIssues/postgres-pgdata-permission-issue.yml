# The problem: 
# when running this workflow with e.g.
#     argo submit --parameter-file input-just_db.yaml  --watch --log FailingIssues/postgres-pgdata-permission-issue.yml 
# one gets the following error message
#    chmod: changing permissions of '/within-container-mount-point/junk/pgdata-results': Operation not permitted
# that gets triggered by 3dcitydb-start-db.
#
# Now this can be explained by the fact that the psql-data-permission-fix step
# is not effective (refer to FailingIssues/creating-directory-issue.yml for
# more on this matter).
# Yet, if prior to running the worklow one does manually created the target
# directory and provides it with the ownership expected by createdb (within the
# postgres container) with
# $ mkdir junk/pgdata-results   # junk is here the value of experiment_output_dir
# $ sudo chown 999 junk/pgdata-results   # 999 is the postgres uid 
# then error message will be changed to
#    chmod: changing permissions of '/within-container-mount-point/junk/pgdata-results': Unknown error 526
# Notice that, in this precise context
# $ docker run  -v /data/host:/local_mount -it tumgis/3dcitydb-postgis:v4.0.2 ls -al /local_mount/junk/pgdata-results
# will return
#     drwx------ 1 1000 1000 64 Jan  6 13:24 pgdata-results
# meaning that ownership is mapped by `minikube mount`.
#
# Reproducing this failure at the docker level (that is the docker proposed
# by minikube) can be done with e.g. 
#    docker run -e "PGDATA=/local_mount/junk/pgdata" -v /data/host:/local_mount -it tumgis/3dcitydb-postgis:v4.0.2 
# where it is assumed that /data/host was created with a "bind mount" like
#    minikube mount `pwd`:/data/host &
#    mkdir junk
#
# Yet, if one uses a minikube internal directory then postgres will initialize
# properly. For example
# $ minikube ssh "sudo mkdir -p /data2/junk"
# $ docker run -e "PGDATA=/data2_mnt/junk/pgdata" -v /data2:/data2_mnt -e "POSTGRES_PASSWORD=dummy" -it tumgis/3dcitydb-postgis:v4.0.2
# will run smoothly.
#
### Workaround attempt
# Mapping of uid can be done at
#   minikube mount --uid=999 `pwd`:/data/host &
# in which the 
#   argo submit --parameter-file input-just_db.yaml  --watch --log FailingIssues/postgres-pgdata-permission-issue.yml
# will partially pass the createdb stage to reach the next stag that goes
#    LOG:  could not link file "pg_wal/xlogtemp.39" to 
#    "pg_wal/000000010000000000000001": Operation not permitted
# 
###
# The above is a well known issue (at least of the docker community) as 
# illustrated by the following discussions that cleanly describes the problem,
# the associated frustration as well as possible workarounds (none of them
# working in the argo workflows context): 
#    https://stackoverflow.com/questions/60192819/cant-get-either-postgres-permissions-or-pvc-working-in-aks
#    https://github.com/docker-library/postgres/issues/548

# Search below for the "ISSUE" string to get directly were things hurt.
# 
# Notes 
# * VolumeMount doesn't not support mountOptions (here is the doc
#   https://argoproj.github.io/argo-workflows/fields/#volumemount )
#   This prevents applying possible k8s level solutions using things like
#      mountOptions:
#        - dir_mode=0777
#        - file_mode=0777 
# * MongoDB users seem to face a similar problem as chown by this StackOverflow
#   https://stackoverflow.com/questions/51200115/chown-changing-ownership-of-data-db-operation-not-permitted/

apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: parameters-
spec:
  entrypoint: main
  volumes:
  - name: workdir
    hostPath:
      path: /data/host
  arguments:
    parameters:
    - name: database_name
    - name: database_password
    - name: database_user
    - name: experiment_output_dir
    - name: persistedVolume   
      value: /within-container-mount-point/

  templates:
  - name: main
    steps:
    - - name: psql-data-permission-fix-step
        template: psql-data-permission-fix
        arguments:
          parameters:
          - name: output_dir
            value: "{{workflow.parameters.experiment_output_dir}}/pgdata-results"
          - name: persistedVolume
            value: "{{workflow.parameters.persistedVolume}}"

    - - name: 3dcitydb-start-db
        templateRef:
          name: workflow-database-templaterefs
          template: 3dcitydb-daemon-persiste-volume
        arguments:
          parameters:
          - name: database_name
            value: "{{workflow.parameters.database_name}}"
          - name: persistedVolume
            value: "{{workflow.parameters.persistedVolume}}"
          - name: password
            value: "{{workflow.parameters.database_password}}"
          - name: user
            value: "{{workflow.parameters.database_user}}"
          - name: port
            value: "{{workflow.parameters.database_port}}"  
          - name: output_dir
            value: "{{workflow.parameters.experiment_output_dir}}/pgdata-results"  
    
    - - name: client-check
        template: 3dcitydb-client-check-template
        arguments:
          parameters:
          - name: command
            value: "PGPASSWORD={{workflow.parameters.database_password}} psql -h {{steps.3dcitydb-start-db.ip}} -p {{workflow.parameters.database_port}} -U {{workflow.parameters.database_user}} -d {{workflow.parameters.database_name}} -c 'SELECT * FROM pg_catalog.pg_tables'"

  - name: 3dcitydb-client-check-template
    inputs:
      parameters:
      - name: command
    container:
      image: postgres:latest
      imagePullPolicy: IfNotPresent
      command: [ "/bin/bash", "-c" ]
      args: [ "{{inputs.parameters.command}}" ]
              
  - name: psql-data-permission-fix
    inputs:
      parameters:
      - name: output_dir
      - name: persistedVolume
    container:
      image: busybox:latest
      command: [ "mkdir","-p","-m", "777", "{{inputs.parameters.persistedVolume}}{{inputs.parameters.output_dir}}", "&&", "chown", "999", "{{inputs.parameters.persistedVolume}}{{inputs.parameters.output_dir}}" ]
      volumeMounts:
      - name: workdir
        mountPath: "{{inputs.parameters.persistedVolume}}"

